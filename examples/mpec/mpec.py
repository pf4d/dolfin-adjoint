#!/usr/bin/env python
# -*- coding: utf-8 -*-

# .. py:currentmodule:: dolfin_adjoint
#
# Mathematical Programs with Equilibrium Constraints
# ==================================================
#
# .. sectionauthor:: Simon W. Funke <simon@simula.no>
#
# This demo solves example 5.2 of :cite:`hintermueller2011`.
#
# Problem definition
# ******************
#
# This problem is to minimise
#
# .. math::
#       \min_{y, u} \frac{1}{2} || y - y_d ||^2_{\Omega} + \frac{\nu}{2} || u ||^2_{\Omega}
#
# subject to the variational inequality
#
# .. math::
#       ( \nabla y, \nabla (v - y) )_\Omega &\ge (f + u, v - y)_\Omega \qquad \forall v \ge 0, v = 0 \ \mathrm{on}\ \delta \Omega, \\
#       y &\ge 0, \\
#       y &= 0 \quad \mathrm{on}\ \delta \Omega,
#
# and control constraints
#
# .. math::
#          a \le u \le b \qquad \forall x \in \Omega,
#
#
# where :math:`u` is the control, :math:`y` is the solution of the
# variational inequality, :math:`y_d` is data to be matched, :math:`f`
# is a prescribed source term, :math:`\nu` is a regularisation
# parameter and :math:`a, b` are upper and lower bounds for the
# control.
#
# This problem is fundamentally different to a PDE-constrained
# optimisation problem in that the constraint is not a PDE, but a
# variational inequality.  Such problems are called Mathematical
# Programs with Equilibrium Constraints (MPECs) and have applications
# in engineering design (e.g. to determine optimal trajectories for
# robots :cite:`yunt2005` or process optimisation in chemical
# engineering :cite:`baumrucker2008`) and in economics (e.g. in
# leader-follower games :cite:`leyffer2005` and optimal pricing
# :cite:`lawphongpanich2004`).
#
# Even though it is known that the above problem admits a unique
# solution, there are some difficulties to be considered when solving
# MPECs:
#
#  - the set of feasible points is in general not necessarly convex or connected, and
#  - the reduced problem is not FrÃ©chet-differentiable.
#
# Following :cite:`hintermueller2011`, we will overcome these issues
# in the next section with a penalisation approach.  For a more
# thorough discussion on MPECs, see :cite:`luo1996` and the references
# therein.
#
# Penalisation technique
# **********************
#
# A common approach for solving variational inequalities is to
# approximate them by a sequence of nonlinear PDEs with a penalisation
# term.  We transform the above problem into a sequence of
# PDE-constrained optimisation problems, which can be solved with
# ``dolfin-adjoint``.
#
# For the above problem we use the approximation
#
# .. math::
#       (\nabla y, \nabla v)_\Omega + \frac{1}{\alpha} (\pi(y), v)_\Omega = (f + u, v)_\Omega \qquad \forall v, \\
#
# where :math:`\alpha > 0` is the penalty parameter and the penalty term
# is defined as
#
# .. math::
#       \pi(y) = -\max(0, y).
#
#
# This approximation yields solutions which converge to the solution of
# the variational inequality as :math:`\alpha \to 0` (see chapter IV of
# :cite:`kinderlehrer2000`).
#
# In order to be able to apply a gradient-based optimisation method, we
# need differentiabilty of the above equation.  The :math:`\max`
# operator is not differentiable at the origin, and hence it is replaced
# by a smooth (:math:`C^1`) approximation (plot modified from
# :cite:`hintermueller2011`):
#
# .. math::
#       {\max}_{\epsilon}(0, y) =
#       \begin{cases}
#       y - \frac{\epsilon}{2} & \mbox{if } y \ge 0, \\
#                     \frac{y^2}{2\epsilon}  & \mbox{if } y \in (0, \epsilon), \\
#                     0                  & \mbox{if } y \le 0.
#       \end{cases}
#
#
# .. image:: mpec-smoothmax.jpg
#     :scale: 50
#     :align: center
#
# The domain for the example problem is the unit square :math:`\Omega =
# (0, 1)^2`.  The data and the source term are given as :math:`y_d(x, y)
# = f(x, y) = -|xy - 0.5| + 0.25`.  The remaining parameters are
# :math:`a = 0.01`, :math:`b = 0.03` and :math:`\nu = 0.01`.
#
# Implementation
# **************
#
# First, the :py:mod:`dolfin` and :py:mod:`dolfin_adjoint` modules are
# imported. We also tell DOLFIN to only print error messages to keep the
# output comprehensible:

from dolfin import *
from dolfin_adjoint import *
set_log_level(ERROR)

# Next, we define the smooth approximation :math:`\max_{\epsilon}` of
# the maximum operator:

def smoothmax(r, eps=1e-4):
  return conditional(gt(r, eps), r - eps/2, conditional(lt(r, 0), 0, r**2 / (2*eps)))

# Now, we are ready to mesh the domain and define the discrete function
# spaces.  For this example we use piecewise linear, continuous finite
# elements for both the solution and control.

mesh = UnitSquareMesh(128, 128)
V = FunctionSpace(mesh, "CG", 1)  # The function space for the solution and control functions
y = Function(V, name="Solution")
u = Function(V, name="Control")
w = TestFunction(V)

# Next, we define and solve the variational formulation of the PDE
# constraint with the penalisation parameter set to
# :math:`\alpha=10^{-2}`.  This initial value of :math:`\alpha` will
# then be iteratively reduced to better approximate the underlying MPEC.

alpha = Constant(1e-2)
# The source term
f = interpolate(Expression("-std::abs(x[0]*x[1] - 0.5) + 0.25"), V)
F = inner(grad(y), grad(w))*dx - 1 / alpha * inner(smoothmax(-y), w)*dx - inner(f + u, w)*dx  
bc = DirichletBC(V, 0.0, "on_boundary")
solve(F == 0, y, bcs=bc)

# With the forward problem solved once, :py:mod:`dolfin_adjoint` has
# built a *tape* of the forward model; it will use this tape to drive
# the optimisation, by repeatedly solving the forward model and the
# adjoint model for varying control inputs.
#
# We finish the initialisation part by defining the functional of
# interest, the optimisation parameter and creating the :doc:`reduced
# functional <../maths/2-problem>` object:

yd = Function(f, name="Data")
nu = 0.01
J = Functional(0.5*inner(y - yd, y - yd)*dx + nu/2*inner(u, u)*dx)

# Formulate the reduced problem
m = Control(u)  # Create a parameter from u, as it is the variable we want to optimise
alpha_m = Control(alpha)  # Also tell dolfin-adjoint that alpha is a parameter, 
                          # this will allow us to modify its value on the tape
Jhat = ReducedFunctional(J, m)

# Create output files
ypvd = File("output/y_opt.pvd") 
upvd = File("output/u_opt.pvd") 

# Next, we implement the main loop of the algorithm. In every iteration
# we will halve the penalisation parameter and (re-)solve the
# optimisation problem. The optimised control value will then be used as
# an initial guess for the next optimisation problem.
#
# We begin by defining the loop and updating the :math:`\alpha` value.

for i in range(4):
  # Update the penalisation value
  alpha.assign(float(alpha)/2)
  info_green("Set alpha to %f." % float(alpha))

# We rely on a useful property of dolfin-adjoint here: if a ``Constant``
# object is used as a control (here achieved by creating the
# :py:class:`Control <dolfin_adjoint.Control>` object
# above), dolfin-adjoint does not copy that ``Constant`` object, but
# keeps a reference to it instead.  That means that assigning a new
# value to ``alpha`` has the effect that the optimisation routine will
# automatically use that new value.
#
# Next we solve the optimisation problem for the current ``alpha``.  We
# use the ``L-BFGS-B`` optimisation algorithm here :cite:`zhu1997b` and
# select a set of sensible stopping criteria:

  u_opt = minimize(Jhat, method="L-BFGS-B", bounds=(0.01, 0.03), options={"gtol": 1e-12, "ftol": 1e-100})

# The following step is optional and implements a performance
# improvement. The idea is to use the optimised state solution as an
# initial guess for the Newton solver in the next optimisation round.
# It demonstrates how one can access and modify variables on the
# ``dolfin-adjoint`` tape.
#
# First, we extract the optimised state (the ``y`` function) from the
# tape. This is done with the ``DolfinAdjointVariable.tape_value()``
# function. By default it returns the last known iteration of that
# function on the tape, which is exactly what we want here:

  y_opt = DolfinAdjointVariable(y).tape_value()

# The next line modifies the tape such that the initial guess for ``y``
# (to be used in the Newton solver in the forward problem) is set to
# ``y_opt``.  This is achieved with the function
# :py:func:`replace_parameter_value
# <dolfin_adjoint.replace_parameter_value>` (or alternatively with
# :py:func:`replace_tape_value <dolfin_adjoint.replace_tape_value>`, if
# we needed more control, e.g. replace a non-initial value function):

  replace_parameter_value(Control(y), y_opt)

# Finally, we store the optimal state and control to disk and print some
# statistics:

  ypvd << y_opt
  upvd << u_opt
  feasibility = sqrt(assemble(inner((Max(Constant(0.0), -y_opt)), (Max(Constant(0.0), -y_opt)))*dx))
  info_green("Feasibility: %s" % feasibility)
  info_green("Norm of y: %s" % sqrt(assemble(inner(y_opt, y_opt)*dx)))
  info_green("Norm of u_opt: %s" % sqrt(assemble(inner(u_opt, u_opt)*dx)))

# The example code can be found in ``examples/mpec/`` in the
# ``dolfin-adjoint`` source tree, and executed as follows:
#
# .. code-block:: bash
#
#   $ python mpec.py
#   Set alpha to 0.005000.
#   ...
#   Feasibility: 0.000350169305795
#   Norm of y: 0.0022809992669
#   Norm of u_opt: 0.021222354644
#
#   ...
#
#   Tit   = total number of iterations
#   Tnf   = total number of function evaluations
#   Tnint = total number of segments explored during Cauchy searches
#   Skip  = number of BFGS updates skipped
#   Nact  = number of active bounds at final generalized Cauchy point
#   Projg = norm of the final projected gradient
#   F     = final function value
#
#              * * *
#
#      N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
#   16641      7      8     85     0 15982   6.192D-13   1.206D-02
#     F =   1.2064186622885919E-002
#
#   CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL
#
#    Cauchy                time 1.320E-03 seconds.
#    Subspace minimization time 9.575E-04 seconds.
#    Line search           time 8.612E+00 seconds.
#
#    Total User time 9.847E+00 seconds.
#
#   Feasibility: 8.56988113345e-05
#   Norm of y: 0.00232945325255
#   Norm of u_opt: 0.0217167930891
#
#
# The optimal control and state can be visualised by opening
# ``output/u.pvd`` and ``output/y.pvd`` in paraview. The optimal control
# should look like the image on the left and the optimal state like the
# image on the right:
#
# .. image:: mpec.png
#     :scale: 50
#     :align: center
#
# .. rubric:: References
#
# .. bibliography:: /documentation/mpec/mpec.bib
#    :cited:
#    :labelprefix: 5E-
